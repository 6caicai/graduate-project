#!/usr/bin/env python3
"""
è®¡ç®—ç›¸å¯¹äºæ€»å›¾ç‰‡æ•°çš„è¯¯åˆ¤ç‡
"""
import json
from pathlib import Path
from collections import Counter

REPO_ROOT = Path(__file__).resolve().parents[2]
BACKEND_DIR = REPO_ROOT / "campusphoto" / "backend"
ERROR_JSON = BACKEND_DIR / "error_cases.json"

def get_total_image_count():
    """ç»Ÿè®¡æ€»å›¾ç‰‡æ•°é‡"""
    cases = load_error_cases()
    if not cases:
        return 0, {}
    
    # ç»Ÿè®¡å„ä¸»é¢˜çš„æ€»å›¾ç‰‡æ•°ï¼ˆåŒ…æ‹¬æ­£ç¡®å’Œé”™è¯¯çš„ï¼‰
    theme_counts = Counter()
    total_images = len(cases)
    
    for case in cases:
        if isinstance(case, dict):
            expected = case.get("expected_theme", "")
            if expected:
                theme_counts[expected] += 1
    
    return total_images, dict(theme_counts)

def load_error_cases():
    """åŠ è½½æ‰€æœ‰æ¡ˆä¾‹æ•°æ®"""
    if not ERROR_JSON.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {ERROR_JSON}")
        return []
    
    with open(ERROR_JSON, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data if isinstance(data, list) else []

def calculate_misclassification_rates():
    """è®¡ç®—ç›¸å¯¹äºæ€»å›¾ç‰‡æ•°çš„è¯¯åˆ¤ç‡"""
    total_images, theme_counts = get_total_image_count()
    
    # ç”¨æˆ·æä¾›çš„æ ·æœ¬ç»Ÿè®¡
    SAMPLE_STATS = {
        "åŠ¨ç‰©->è¡—æ™¯": {"ai_error": 3, "dataset_error": 0, "total": 3},
        "åŠ¨ç‰©->äººåƒ": {"ai_error": 188, "dataset_error": 26, "total": 214},
        "åŠ¨ç‰©->é£Ÿç‰©å’Œé™ç‰©": {"ai_error": 43, "dataset_error": 0, "total": 43},
        "åŠ¨ç‰©->è‡ªç„¶é£å…‰": {"ai_error": 730, "dataset_error": 0, "total": 730},
        "è¡—æ™¯->åŠ¨ç‰©": {"ai_error": 82, "dataset_error": 5, "total": 87},
        "äººåƒ->åŠ¨ç‰©": {"ai_error": 449, "dataset_error": 561, "total": 1010},
        "äººåƒ->è¡—æ™¯": {"ai_error": 48, "dataset_error": 50, "total": 98},
    }
    
    # åˆ†æé”™è¯¯åˆ†ç±»
    cases = load_error_cases()
    category_stats = {}
    
    for case in cases:
        if not isinstance(case, dict):
            continue
            
        expected = case.get("expected_theme", "")
        predicted = case.get("predicted_theme", "")
        
        if expected and predicted and expected != predicted:
            key = f"{expected}->{predicted}"
            if key not in category_stats:
                category_stats[key] = []
            category_stats[key].append(case)
    
    print(f"ğŸ“Š æ€»å›¾ç‰‡æ•°é‡: {total_images}")
    print(f"ğŸ“ˆ å„ä¸»é¢˜å›¾ç‰‡åˆ†å¸ƒ:")
    for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  {theme}: {count} å¼  ({count/total_images:.1%})")
    
    print(f"\nğŸ“‹ ç›¸å¯¹äºæ€»å›¾ç‰‡æ•°çš„è¯¯åˆ¤ç‡åˆ†æ:")
    print("=" * 100)
    print(f"{'é”™è¯¯ç±»åˆ«':25} | {'é”™è¯¯æ•°':6} | {'AIè¯¯åˆ¤':8} | {'æ•°æ®é›†é”™è¯¯':10} | {'æ€»è¯¯åˆ¤ç‡':8} | {'AIè¯¯åˆ¤ç‡':8} | {'æ ·æœ¬æ•°':6}")
    print("-" * 100)
    
    total_errors = 0
    total_ai_errors = 0
    total_dataset_errors = 0
    
    # æŒ‰é”™è¯¯æ•°æ’åº
    sorted_categories = sorted(category_stats.items(), key=lambda x: len(x[1]), reverse=True)
    
    for category, cases in sorted_categories:
        error_count = len(cases)
        total_errors += error_count
        
        if category in SAMPLE_STATS:
            sample = SAMPLE_STATS[category]
            ai_error_rate = sample["ai_error"] / sample["total"] if sample["total"] > 0 else 0
            dataset_error_rate = sample["dataset_error"] / sample["total"] if sample["total"] > 0 else 0
            
            estimated_ai_errors = int(error_count * ai_error_rate)
            estimated_dataset_errors = int(error_count * dataset_error_rate)
            
            total_ai_errors += estimated_ai_errors
            total_dataset_errors += estimated_dataset_errors
            
            # è®¡ç®—ç›¸å¯¹äºæ€»å›¾ç‰‡æ•°çš„è¯¯åˆ¤ç‡
            total_misclassification_rate = error_count / total_images
            ai_misclassification_rate = estimated_ai_errors / total_images
            
            print(f"{category:25} | {error_count:6} | {estimated_ai_errors:8} | {estimated_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {sample['total']:6}")
        else:
            # ä¿å®ˆä¼°è®¡
            estimated_ai_errors = int(error_count * 0.5)
            estimated_dataset_errors = error_count - estimated_ai_errors
            
            total_ai_errors += estimated_ai_errors
            total_dataset_errors += estimated_dataset_errors
            
            total_misclassification_rate = error_count / total_images
            ai_misclassification_rate = estimated_ai_errors / total_images
            
            print(f"{category:25} | {error_count:6} | {estimated_ai_errors:8} | {estimated_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {'æ— ':6}")
    
    print("-" * 100)
    total_misclassification_rate = total_errors / total_images
    ai_misclassification_rate = total_ai_errors / total_images
    dataset_misclassification_rate = total_dataset_errors / total_images
    
    print(f"{'æ€»è®¡':25} | {total_errors:6} | {total_ai_errors:8} | {total_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {'':6}")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"  æ€»å›¾ç‰‡æ•°: {total_images}")
    print(f"  æ€»é”™è¯¯æ•°: {total_errors} ({total_misclassification_rate:.1%})")
    print(f"  AIè¯¯åˆ¤æ•°: {total_ai_errors} ({ai_misclassification_rate:.1%})")
    print(f"  æ•°æ®é›†é”™è¯¯: {total_dataset_errors} ({dataset_misclassification_rate:.1%})")

if __name__ == "__main__":
    calculate_misclassification_rates()
