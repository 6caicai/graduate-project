#!/usr/bin/env python3
"""
æ¸…ç† bdd100k_seg ç›¸å…³æ•°æ®ï¼š
1. å¤‡ä»½ error_cases.json
2. è¿‡æ»¤æ‰åŒ…å« bdd100k_seg çš„è®°å½•
3. åˆ é™¤ result/ ä¸­ç›¸å…³çš„ç›®å½•
"""
import json
import shutil
from pathlib import Path
from datetime import datetime

REPO_ROOT = Path(__file__).resolve().parents[2]
BACKEND_DIR = REPO_ROOT / "campusphoto" / "backend"
ERROR_JSON = BACKEND_DIR / "error_cases.json"
RESULT_DIR = REPO_ROOT / "campusphoto" / "ai" / "exp" / "result"

def backup_file(file_path: Path) -> Path:
    """åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = file_path.parent / f"{file_path.stem}_backup_{timestamp}{file_path.suffix}"
    shutil.copy2(file_path, backup_path)
    print(f"âœ… å·²å¤‡ä»½: {file_path} -> {backup_path}")
    return backup_path

def filter_error_cases():
    """è¿‡æ»¤ error_cases.json ä¸­çš„ bdd100k_seg è®°å½•"""
    if not ERROR_JSON.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {ERROR_JSON}")
        return False
    
    # å¤‡ä»½åŸæ–‡ä»¶
    backup_path = backup_file(ERROR_JSON)
    
    # è¯»å–æ•°æ®
    print("ğŸ“– è¯»å– error_cases.json...")
    with open(ERROR_JSON, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not isinstance(data, list):
        print("âŒ JSON æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨")
        return False
    
    original_count = len(data)
    print(f"ğŸ“Š åŸå§‹è®°å½•æ•°: {original_count}")
    
    # è¿‡æ»¤æ‰åŒ…å« bdd100k_seg çš„è®°å½•
    filtered_data = []
    bdd_count = 0
    
    for item in data:
        if isinstance(item, dict):
            file_path = item.get("file_path", "")
            if "bdd100k_seg" in file_path:
                bdd_count += 1
                continue
        filtered_data.append(item)
    
    print(f"ğŸ—‘ï¸ è¿‡æ»¤æ‰ bdd100k_seg è®°å½•: {bdd_count}")
    print(f"ğŸ“Š å‰©ä½™è®°å½•æ•°: {len(filtered_data)}")
    
    # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
    print("ğŸ’¾ ä¿å­˜è¿‡æ»¤åçš„æ•°æ®...")
    with open(ERROR_JSON, 'w', encoding='utf-8') as f:
        json.dump(filtered_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²æ›´æ–° {ERROR_JSON}")
    return True

def cleanup_result_dirs():
    """åˆ é™¤ result/ ä¸­åŒ…å« bdd100k_seg çš„ç›®å½•"""
    if not RESULT_DIR.exists():
        print(f"âš ï¸ ç»“æœç›®å½•ä¸å­˜åœ¨: {RESULT_DIR}")
        return
    
    print(f"ğŸ” æ‰«æç»“æœç›®å½•: {RESULT_DIR}")
    removed_dirs = []
    
    for item in RESULT_DIR.iterdir():
        if item.is_dir() and "bdd100k_seg" in item.name:
            print(f"ğŸ—‘ï¸ åˆ é™¤ç›®å½•: {item}")
            shutil.rmtree(item)
            removed_dirs.append(item.name)
    
    if removed_dirs:
        print(f"âœ… å·²åˆ é™¤ {len(removed_dirs)} ä¸ªç›¸å…³ç›®å½•: {removed_dirs}")
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°åŒ…å« bdd100k_seg çš„ç»“æœç›®å½•")

def main():
    print("ğŸ§¹ å¼€å§‹æ¸…ç† bdd100k_seg ç›¸å…³æ•°æ®...")
    
    # 1. è¿‡æ»¤ error_cases.json
    if not filter_error_cases():
        print("âŒ è¿‡æ»¤ error_cases.json å¤±è´¥")
        return
    
    # 2. æ¸…ç†ç»“æœç›®å½•
    cleanup_result_dirs()
    
    print("\nğŸ‰ æ¸…ç†å®Œæˆï¼")
    print(f"ğŸ“ å¤‡ä»½ä½ç½®: {BACKEND_DIR}")
    print(f"ğŸ“ ç»“æœç›®å½•: {RESULT_DIR}")

if __name__ == "__main__":
    main()
