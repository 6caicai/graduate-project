#!/usr/bin/env python3
"""
åŸºäº complete_test_report.md çš„æ€»å›¾ç‰‡æ•°é‡æ–°è®¡ç®—è¯¯åˆ¤ç‡
æ€»æµ‹è¯•å›¾ç‰‡: 332,532 å¼ 
é”™è¯¯æ¡ˆä¾‹: 49,417 å¼  (æ¥è‡ª error_cases.json)
"""
import json
from pathlib import Path
from collections import Counter

REPO_ROOT = Path(__file__).resolve().parents[2]
BACKEND_DIR = REPO_ROOT / "campusphoto" / "backend"
ERROR_JSON = BACKEND_DIR / "error_cases.json"

# ä» complete_test_report.md è·å–çš„æ€»å›¾ç‰‡æ•°
TOTAL_TEST_IMAGES = 332532

# ç”¨æˆ·æä¾›çš„æ ·æœ¬ç»Ÿè®¡
SAMPLE_STATS = {
    "åŠ¨ç‰©->è¡—æ™¯": {"ai_error": 3, "dataset_error": 0, "total": 3},
    "åŠ¨ç‰©->äººåƒ": {"ai_error": 188, "dataset_error": 26, "total": 214},
    "åŠ¨ç‰©->é£Ÿç‰©å’Œé™ç‰©": {"ai_error": 43, "dataset_error": 0, "total": 43},
    "åŠ¨ç‰©->è‡ªç„¶é£å…‰": {"ai_error": 730, "dataset_error": 0, "total": 730},
    "è¡—æ™¯->åŠ¨ç‰©": {"ai_error": 82, "dataset_error": 5, "total": 87},
    "äººåƒ->åŠ¨ç‰©": {"ai_error": 449, "dataset_error": 561, "total": 1010},
    "äººåƒ->è¡—æ™¯": {"ai_error": 48, "dataset_error": 50, "total": 98},
}

def load_error_cases():
    """åŠ è½½é”™è¯¯æ¡ˆä¾‹æ•°æ®"""
    if not ERROR_JSON.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {ERROR_JSON}")
        return []
    
    with open(ERROR_JSON, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data if isinstance(data, list) else []

def calculate_corrected_misclassification_rates():
    """åŸºäºæ€»æµ‹è¯•å›¾ç‰‡æ•°è®¡ç®—è¯¯åˆ¤ç‡"""
    cases = load_error_cases()
    if not cases:
        return
    
    # åˆ†æé”™è¯¯åˆ†ç±»
    category_stats = {}
    theme_counts = Counter()
    
    for case in cases:
        if not isinstance(case, dict):
            continue
            
        expected = case.get("expected_theme", "")
        predicted = case.get("predicted_theme", "")
        
        if expected:
            theme_counts[expected] += 1
            
        if expected and predicted and expected != predicted:
            key = f"{expected}->{predicted}"
            if key not in category_stats:
                category_stats[key] = []
            category_stats[key].append(case)
    
    print(f"ğŸ“Š åŸºäº complete_test_report.md çš„è¯¯åˆ¤ç‡åˆ†æ:")
    print(f"æ€»æµ‹è¯•å›¾ç‰‡æ•°: {TOTAL_TEST_IMAGES:,} å¼ ")
    print(f"é”™è¯¯æ¡ˆä¾‹æ•°: {len(cases):,} å¼ ")
    print(f"æ€»ä½“é”™è¯¯ç‡: {len(cases)/TOTAL_TEST_IMAGES:.1%}")
    print("=" * 100)
    print(f"{'é”™è¯¯ç±»åˆ«':25} | {'é”™è¯¯æ•°':6} | {'AIè¯¯åˆ¤':8} | {'æ•°æ®é›†é”™è¯¯':10} | {'æ€»è¯¯åˆ¤ç‡':8} | {'AIè¯¯åˆ¤ç‡':8} | {'æ ·æœ¬æ•°':6}")
    print("-" * 100)
    
    total_ai_errors = 0
    total_dataset_errors = 0
    
    # æŒ‰é”™è¯¯æ•°æ’åº
    sorted_categories = sorted(category_stats.items(), key=lambda x: len(x[1]), reverse=True)
    
    for category, cases in sorted_categories:
        error_count = len(cases)
        
        if category in SAMPLE_STATS:
            sample = SAMPLE_STATS[category]
            ai_error_rate = sample["ai_error"] / sample["total"] if sample["total"] > 0 else 0
            dataset_error_rate = sample["dataset_error"] / sample["total"] if sample["total"] > 0 else 0
            
            estimated_ai_errors = int(error_count * ai_error_rate)
            estimated_dataset_errors = int(error_count * dataset_error_rate)
            
            total_ai_errors += estimated_ai_errors
            total_dataset_errors += estimated_dataset_errors
            
            # è®¡ç®—ç›¸å¯¹äºæ€»æµ‹è¯•å›¾ç‰‡æ•°çš„è¯¯åˆ¤ç‡
            total_misclassification_rate = error_count / TOTAL_TEST_IMAGES
            ai_misclassification_rate = estimated_ai_errors / TOTAL_TEST_IMAGES
            
            print(f"{category:25} | {error_count:6} | {estimated_ai_errors:8} | {estimated_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {sample['total']:6}")
        else:
            # ä¿å®ˆä¼°è®¡
            estimated_ai_errors = int(error_count * 0.5)
            estimated_dataset_errors = error_count - estimated_ai_errors
            
            total_ai_errors += estimated_ai_errors
            total_dataset_errors += estimated_dataset_errors
            
            total_misclassification_rate = error_count / TOTAL_TEST_IMAGES
            ai_misclassification_rate = estimated_ai_errors / TOTAL_TEST_IMAGES
            
            print(f"{category:25} | {error_count:6} | {estimated_ai_errors:8} | {estimated_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {'æ— ':6}")
    
    print("-" * 100)
    total_misclassification_rate = len(cases) / TOTAL_TEST_IMAGES
    ai_misclassification_rate = total_ai_errors / TOTAL_TEST_IMAGES
    dataset_misclassification_rate = total_dataset_errors / TOTAL_TEST_IMAGES
    
    print(f"{'æ€»è®¡':25} | {len(cases):6} | {total_ai_errors:8} | {total_dataset_errors:10} | {total_misclassification_rate:7.1%} | {ai_misclassification_rate:7.1%} | {'':6}")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"  æ€»æµ‹è¯•å›¾ç‰‡æ•°: {TOTAL_TEST_IMAGES:,}")
    print(f"  æ€»é”™è¯¯æ•°: {len(cases):,} ({len(cases)/TOTAL_TEST_IMAGES:.1%})")
    print(f"  AIè¯¯åˆ¤æ•°: {total_ai_errors:,} ({ai_misclassification_rate:.1%})")
    print(f"  æ•°æ®é›†é”™è¯¯: {total_dataset_errors:,} ({dataset_misclassification_rate:.1%})")
    print(f"  æ­£ç¡®é¢„æµ‹æ•°: {TOTAL_TEST_IMAGES - len(cases):,} ({(TOTAL_TEST_IMAGES - len(cases))/TOTAL_TEST_IMAGES:.1%})")

if __name__ == "__main__":
    calculate_corrected_misclassification_rates()
